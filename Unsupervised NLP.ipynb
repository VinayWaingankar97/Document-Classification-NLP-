{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca1061df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import speech_recognition as sr \n",
    "import os \n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"popular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b10aa31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a62543a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load NLTK stopwords and lemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5754fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"So, Let me make a few sharp points as a collective answer. One, No question the world is more nationalistic than in the past and a lot of that Nationalism is economic nationalism and cultural nationalism. \n",
    "            Second, I would say where India is concerned in a way are a Standard and we are an exception because in this country you could say yes are more Nationalistic but at the same time we don't see a tension between being Nationalistic & being international in the sense of dealing more with the world and engaging more with the world.\n",
    "            So, the Nationalism is not a kind of Negative Sentiment directed at the world infact people generally feel if you're going up, you should be doing more things with the world not less things with the world.\n",
    "            Third, you know in a more multiple of your word nationalistic my world, I think we will see diplomacy take different forms where the old ways of working will now not go away but be tempered by much more, I would say creative innovative ad hoc kind of working arrangements often centering around issues rather than across the board. \n",
    "            So, the Character of internaltional politics will probably change in many ways for you and I agree with you.\n",
    "            I think a lot of Multilateral regimes will come under stress how they survival depends on how they respond to that they will come under stress partly because of this nationalism that I spoke about to some extent they lot of them are alos being critiqued for how will they work or don't work.\n",
    "            So, there is a kind of performance audit on Multilaterail Regimes also going on, sometimes that take very unfair directions because if you do performance Audit with a very self centered nationalistic, then I am not sure, I'd agree with the conclusions of that object but certainly that too is a factor.\n",
    "            So, all in all I would say more complicated world definitely a more interested month possibly a more difficult one but where India is concered you also made a reference to G2, you know that's something that never accepted. We have never been comfortable with I think partly what would also distinguish us from other countries is that we still have a very strong relationship with countries of South.\n",
    "            SO, what you have seen definitely over the last 5 years and you saw recently at the UN is a willingness today to go out engage countries visit more countries and therefore you can see a new energy in foreign affairs.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03ced734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['So, Let me make a few sharp points as a collective answer.', 'One, No question the world is more nationalistic than in the past and a lot of that Nationalism is economic nationalism and cultural nationalism.', \"Second, I would say where India is concerned in a way are a Standard and we are an exception because in this country you could say yes are more Nationalistic but at the same time we don't see a tension between being Nationalistic & being international in the sense of dealing more with the world and engaging more with the world.\", \"So, the Nationalism is not a kind of Negative Sentiment directed at the world infact people generally feel if you're going up, you should be doing more things with the world not less things with the world.\", 'Third, you know in a more multiple of your word nationalistic my world, I think we will see diplomacy take different forms where the old ways of working will now not go away but be tempered by much more, I would say creative innovative ad hoc kind of working arrangements often centering around issues rather than across the board.', 'So, the Character of internaltional politics will probably change in many ways for you and I agree with you.', \"I think a lot of Multilateral regimes will come under stress how they survival depends on how they respond to that they will come under stress partly because of this nationalism that I spoke about to some extent they lot of them are alos being critiqued for how will they work or don't work.\", \"So, there is a kind of performance audit on Multilaterail Regimes also going on, sometimes that take very unfair directions because if you do performance Audit with a very self centered nationalistic, then I am not sure, I'd agree with the conclusions of that object but certainly that too is a factor.\", \"So, all in all I would say more complicated world definitely a more interested month possibly a more difficult one but where India is concered you also made a reference to G2, you know that's something that never accepted.\", 'We have never been comfortable with I think partly what would also distinguish us from other countries is that we still have a very strong relationship with countries of South.', 'SO, what you have seen definitely over the last 5 years and you saw recently at the UN is a willingness today to go out engage countries visit more countries and therefore you can see a new energy in foreign affairs.']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Corpus to Sentence Segmentation\n",
    "sentences = sent_tokenize(corpus)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e86524c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So, Let me make a few sharp points as a collective answer.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3abd8a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One, No question the world is more nationalistic than in the past and a lot of that Nationalism is economic nationalism and cultural nationalism.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1610748b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1f5742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Sentence Segmentation to Tokenization and Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenized_sentences = []\n",
    "for sentence in sentences:\n",
    "    words = word_tokenize(sentence)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    tokenized_sentences.append(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "402d1567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1:\n",
      "\n",
      ", Let make sharp point collective answer .\n",
      "\n",
      "\n",
      "Sentence 2:\n",
      "\n",
      "One , question world nationalistic past lot Nationalism economic nationalism cultural nationalism .\n",
      "\n",
      "\n",
      "Sentence 3:\n",
      "\n",
      "Second , would say India concerned way Standard exception country could say yes Nationalistic time n't see tension Nationalistic & international sense dealing world engaging world .\n",
      "\n",
      "\n",
      "Sentence 4:\n",
      "\n",
      ", Nationalism kind Negative Sentiment directed world infact people generally feel 're going , thing world le thing world .\n",
      "\n",
      "\n",
      "Sentence 5:\n",
      "\n",
      "Third , know multiple word nationalistic world , think see diplomacy take different form old way working go away tempered much , would say creative innovative ad hoc kind working arrangement often centering around issue rather across board .\n",
      "\n",
      "\n",
      "Sentence 6:\n",
      "\n",
      ", Character internaltional politics probably change many way agree .\n",
      "\n",
      "\n",
      "Sentence 7:\n",
      "\n",
      "think lot Multilateral regime come stress survival depends respond come stress partly nationalism spoke extent lot alos critiqued work n't work .\n",
      "\n",
      "\n",
      "Sentence 8:\n",
      "\n",
      ", kind performance audit Multilaterail Regimes also going , sometimes take unfair direction performance Audit self centered nationalistic , sure , 'd agree conclusion object certainly factor .\n",
      "\n",
      "\n",
      "Sentence 9:\n",
      "\n",
      ", would say complicated world definitely interested month possibly difficult one India concered also made reference G2 , know 's something never accepted .\n",
      "\n",
      "\n",
      "Sentence 10:\n",
      "\n",
      "never comfortable think partly would also distinguish u country still strong relationship country South .\n",
      "\n",
      "\n",
      "Sentence 11:\n",
      "\n",
      ", seen definitely last 5 year saw recently UN willingness today go engage country visit country therefore see new energy foreign affair .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Remove Stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_sentences = []\n",
    "for tokenized_sentence in tokenized_sentences:\n",
    "    filtered_sentence = [word for word in tokenized_sentence if word.lower() not in stop_words]\n",
    "    filtered_sentences.append(filtered_sentence)\n",
    "\n",
    "# Display filtered sentences\n",
    "for i, sentence in enumerate(filtered_sentences):\n",
    "    print(f\"Sentence {i + 1}:\\n\")\n",
    "    print(\" \".join(sentence))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365c2195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "098fd1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text\n",
      "0          , Let make sharp point collective answer .\n",
      "1   One , question world nationalistic past lot Na...\n",
      "2   Second , would say India concerned way Standar...\n",
      "3   , Nationalism kind Negative Sentiment directed...\n",
      "4   Third , know multiple word nationalistic world...\n",
      "5   , Character internaltional politics probably c...\n",
      "6   think lot Multilateral regime come stress surv...\n",
      "7   , kind performance audit Multilaterail Regimes...\n",
      "8   , would say complicated world definitely inter...\n",
      "9   never comfortable think partly would also dist...\n",
      "10  , seen definitely last 5 year saw recently UN ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of sentences\n",
    "sentences_1 = [\n",
    "    \", Let make sharp point collective answer .\",\n",
    "    \"One , question world nationalistic past lot Nationalism economic nationalism cultural nationalism .\",\n",
    "    \"Second , would say India concerned way Standard exception country could say yes Nationalistic time n't see tension Nationalistic & international sense dealing world engaging world .\",\n",
    "    \", Nationalism kind Negative Sentiment directed world infact people generally feel 're going , thing world le thing world .\",\n",
    "    \"Third , know multiple word nationalistic world , think see diplomacy take different form old way working go away tempered much , would say creative innovative ad hoc kind working arrangement often centering around issue rather across board .\",\n",
    "    \", Character internaltional politics probably change many way agree .\",\n",
    "    \"think lot Multilateral regime come stress survival depends respond come stress partly nationalism spoke extent lot alos critiqued work n't work .\",\n",
    "    \", kind performance audit Multilaterail Regimes also going , sometimes take unfair direction performance Audit self centered nationalistic , sure , 'd agree conclusion object certainly factor .\",\n",
    "    \", would say complicated world definitely interested month possibly difficult one India concered also made reference G2 , know 's something never accepted .\",\n",
    "    \"never comfortable think partly would also distinguish u country still strong relationship country South .\",\n",
    "    \", seen definitely last 5 year saw recently UN willingness today go engage country visit country therefore see new energy foreign affair .\"\n",
    "]\n",
    "\n",
    "# Create a DataFrame for the sentences\n",
    "df = pd.DataFrame(sentences_1, columns=['text'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "300dd444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>, Let make sharp point collective answer .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One , question world nationalistic past lot Na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Second , would say India concerned way Standar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>, Nationalism kind Negative Sentiment directed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Third , know multiple word nationalistic world...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0         , Let make sharp point collective answer .\n",
       "1  One , question world nationalistic past lot Na...\n",
       "2  Second , would say India concerned way Standar...\n",
       "3  , Nationalism kind Negative Sentiment directed...\n",
       "4  Third , know multiple word nationalistic world..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88f51efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(lambda x: re.sub(r'[^\\w ]+', \"\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f1954a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Let make sharp point collective answer '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab143307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One  question world nationalistic past lot Nationalism economic nationalism cultural nationalism '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fa092d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Second  would say India concerned way Standard exception country could say yes Nationalistic time nt see tension Nationalistic  international sense dealing world engaging world '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b88cec00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Nationalism kind Negative Sentiment directed world infact people generally feel re going  thing world le thing world '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44f319c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Third  know multiple word nationalistic world  think see diplomacy take different form old way working go away tempered much  would say creative innovative ad hoc kind working arrangement often centering around issue rather across board '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4015924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Character internaltional politics probably change many way agree '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b2be103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'think lot Multilateral regime come stress survival depends respond come stress partly nationalism spoke extent lot alos critiqued work nt work '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "518d98b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' kind performance audit Multilaterail Regimes also going  sometimes take unfair direction performance Audit self centered nationalistic  sure  d agree conclusion object certainly factor '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d997b57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' would say complicated world definitely interested month possibly difficult one India concered also made reference G2  know s something never accepted '"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2674b1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'never comfortable think partly would also distinguish u country still strong relationship country South '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4fc8f3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' seen definitely last 5 year saw recently UN willingness today go engage country visit country therefore see new energy foreign affair '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "596c48ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30db49c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text Sentiment\n",
      "0             Let make sharp point collective answer    Neutral\n",
      "1   One  question world nationalistic past lot Nat...   Neutral\n",
      "2   Second  would say India concerned way Standard...  Positive\n",
      "3    Nationalism kind Negative Sentiment directed ...  Negative\n",
      "4   Third  know multiple word nationalistic world ...  Positive\n",
      "5    Character internaltional politics probably ch...  Positive\n",
      "6   think lot Multilateral regime come stress surv...  Negative\n",
      "7    kind performance audit Multilaterail Regimes ...  Positive\n",
      "8    would say complicated world definitely intere...  Positive\n",
      "9   never comfortable think partly would also dist...  Positive\n",
      "10   seen definitely last 5 year saw recently UN w...  Positive\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing steps\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [word for word in words if word.isalnum()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply preprocessing to the 'Review' column\n",
    "df['Processed Review'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Create a function to get sentiment scores\n",
    "def get_sentiment_score(text):\n",
    "    sentiment = analyzer.polarity_scores(text)\n",
    "    return sentiment\n",
    "\n",
    "# Apply sentiment analysis to the 'Processed Review' column\n",
    "df['Sentiment Scores'] = df['Processed Review'].apply(get_sentiment_score)\n",
    "\n",
    "# Extract the compound sentiment score from the VADER analysis\n",
    "df['Sentiment'] = df['Sentiment Scores'].apply(lambda x: 'Positive' if x['compound'] > 0 else ('Negative' if x['compound'] < 0 else 'Neutral'))\n",
    "\n",
    "# Display the final DataFrame with sentiment analysis results\n",
    "print(df[['text', 'Sentiment']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e6f2547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Processed Review</th>\n",
       "      <th>Sentiment Scores</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Let make sharp point collective answer</td>\n",
       "      <td>let make sharp point collective answer</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One  question world nationalistic past lot Nat...</td>\n",
       "      <td>one question world nationalistic past lot nati...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0            Let make sharp point collective answer    \n",
       "1  One  question world nationalistic past lot Nat...   \n",
       "\n",
       "                                    Processed Review  \\\n",
       "0             let make sharp point collective answer   \n",
       "1  one question world nationalistic past lot nati...   \n",
       "\n",
       "                                    Sentiment Scores Sentiment  \n",
       "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   Neutral  \n",
       "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   Neutral  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e89e52d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One  question world nationalistic past lot Nationalism economic nationalism cultural nationalism '"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28de486f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one question world nationalistic past lot nationalism economic nationalism cultural nationalism'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Processed Review\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bbe0d70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment Scores\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dfb0e9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Nationalism kind Negative Sentiment directed world infact people generally feel re going  thing world le thing world '"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6698a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nationalism kind negative sentiment directed world infact people generally feel going thing world le thing world'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Processed Review\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e51b36bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.175, 'neu': 0.664, 'pos': 0.161, 'compound': -0.0772}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment Scores\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9d7bbb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'processed_review', 'sentiment_scores', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing column names to lower case and removing unwanted spaces \n",
    "df.columns=df.columns.str.lower()\n",
    "df.columns=df.columns.str.replace(\" \",\"_\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d1ba98e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sentiment.replace(\"Positive\", 2, inplace=True)\n",
    "df.sentiment.replace(\"Negative\", 0, inplace=True)\n",
    "df.sentiment.replace(\"Neutral\", 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6fd00558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed_review</th>\n",
       "      <th>sentiment_scores</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Let make sharp point collective answer</td>\n",
       "      <td>let make sharp point collective answer</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One  question world nationalistic past lot Nat...</td>\n",
       "      <td>one question world nationalistic past lot nati...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Second  would say India concerned way Standard...</td>\n",
       "      <td>second would say india concerned way standard ...</td>\n",
       "      <td>{'neg': 0.081, 'neu': 0.739, 'pos': 0.18, 'com...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nationalism kind Negative Sentiment directed ...</td>\n",
       "      <td>nationalism kind negative sentiment directed w...</td>\n",
       "      <td>{'neg': 0.175, 'neu': 0.664, 'pos': 0.161, 'co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Third  know multiple word nationalistic world ...</td>\n",
       "      <td>third know multiple word nationalistic world t...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.777, 'pos': 0.223, 'comp...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0            Let make sharp point collective answer    \n",
       "1  One  question world nationalistic past lot Nat...   \n",
       "2  Second  would say India concerned way Standard...   \n",
       "3   Nationalism kind Negative Sentiment directed ...   \n",
       "4  Third  know multiple word nationalistic world ...   \n",
       "\n",
       "                                    processed_review  \\\n",
       "0             let make sharp point collective answer   \n",
       "1  one question world nationalistic past lot nati...   \n",
       "2  second would say india concerned way standard ...   \n",
       "3  nationalism kind negative sentiment directed w...   \n",
       "4  third know multiple word nationalistic world t...   \n",
       "\n",
       "                                    sentiment_scores  sentiment  \n",
       "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          1  \n",
       "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          1  \n",
       "2  {'neg': 0.081, 'neu': 0.739, 'pos': 0.18, 'com...          2  \n",
       "3  {'neg': 0.175, 'neu': 0.664, 'pos': 0.161, 'co...          0  \n",
       "4  {'neg': 0.0, 'neu': 0.777, 'pos': 0.223, 'comp...          2  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80b7e0f",
   "metadata": {},
   "source": [
    "**Feature Extraction - Bag of words - Count Vectorizer ( Document Term Matrix Approach)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7efc6d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer #DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b6aa27e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_words = CountVectorizer().fit(df['processed_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "90708b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    }
   ],
   "source": [
    "print(len(bag_words.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "370cf74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7)\t1\n",
      "  (0, 18)\t1\n",
      "  (0, 65)\t1\n",
      "  (0, 68)\t1\n",
      "  (0, 89)\t1\n",
      "  (0, 109)\t1\n",
      "  (1, 29)\t1\n",
      "  (1, 39)\t1\n",
      "  (1, 66)\t1\n",
      "  (1, 75)\t3\n",
      "  (1, 76)\t1\n",
      "  (1, 84)\t1\n",
      "  (1, 86)\t1\n",
      "  (1, 93)\t1\n",
      "  (1, 137)\t1\n",
      "  (2, 23)\t1\n",
      "  (2, 25)\t1\n",
      "  (2, 26)\t1\n",
      "  (2, 30)\t1\n",
      "  (2, 42)\t1\n",
      "  (2, 43)\t1\n",
      "  (2, 54)\t1\n",
      "  (2, 59)\t1\n",
      "  (2, 76)\t2\n",
      "  (2, 80)\t1\n",
      "  :\t:\n",
      "  (9, 99)\t1\n",
      "  (9, 112)\t1\n",
      "  (9, 115)\t1\n",
      "  (9, 117)\t1\n",
      "  (9, 125)\t1\n",
      "  (9, 138)\t1\n",
      "  (10, 3)\t1\n",
      "  (10, 26)\t2\n",
      "  (10, 31)\t1\n",
      "  (10, 40)\t1\n",
      "  (10, 41)\t1\n",
      "  (10, 47)\t1\n",
      "  (10, 51)\t1\n",
      "  (10, 63)\t1\n",
      "  (10, 79)\t1\n",
      "  (10, 95)\t1\n",
      "  (10, 101)\t1\n",
      "  (10, 104)\t1\n",
      "  (10, 105)\t1\n",
      "  (10, 123)\t1\n",
      "  (10, 128)\t1\n",
      "  (10, 129)\t1\n",
      "  (10, 131)\t1\n",
      "  (10, 133)\t1\n",
      "  (10, 139)\t1\n"
     ]
    }
   ],
   "source": [
    "message_bagwords = bag_words.transform(df['processed_review'])\n",
    "print(message_bagwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0293ff94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 141)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_bagwords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d057ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = message_bagwords\n",
    "y = df[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aaeee2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7)\t1\n",
      "  (0, 18)\t1\n",
      "  (0, 65)\t1\n",
      "  (0, 68)\t1\n",
      "  (0, 89)\t1\n",
      "  (0, 109)\t1\n",
      "  (1, 29)\t1\n",
      "  (1, 39)\t1\n",
      "  (1, 66)\t1\n",
      "  (1, 75)\t3\n",
      "  (1, 76)\t1\n",
      "  (1, 84)\t1\n",
      "  (1, 86)\t1\n",
      "  (1, 93)\t1\n",
      "  (1, 137)\t1\n",
      "  (2, 23)\t1\n",
      "  (2, 25)\t1\n",
      "  (2, 26)\t1\n",
      "  (2, 30)\t1\n",
      "  (2, 42)\t1\n",
      "  (2, 43)\t1\n",
      "  (2, 54)\t1\n",
      "  (2, 59)\t1\n",
      "  (2, 76)\t2\n",
      "  (2, 80)\t1\n",
      "  :\t:\n",
      "  (9, 99)\t1\n",
      "  (9, 112)\t1\n",
      "  (9, 115)\t1\n",
      "  (9, 117)\t1\n",
      "  (9, 125)\t1\n",
      "  (9, 138)\t1\n",
      "  (10, 3)\t1\n",
      "  (10, 26)\t2\n",
      "  (10, 31)\t1\n",
      "  (10, 40)\t1\n",
      "  (10, 41)\t1\n",
      "  (10, 47)\t1\n",
      "  (10, 51)\t1\n",
      "  (10, 63)\t1\n",
      "  (10, 79)\t1\n",
      "  (10, 95)\t1\n",
      "  (10, 101)\t1\n",
      "  (10, 104)\t1\n",
      "  (10, 105)\t1\n",
      "  (10, 123)\t1\n",
      "  (10, 128)\t1\n",
      "  (10, 129)\t1\n",
      "  (10, 131)\t1\n",
      "  (10, 133)\t1\n",
      "  (10, 139)\t1\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "64fdfe1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1\n",
      "1     1\n",
      "2     2\n",
      "3     0\n",
      "4     2\n",
      "5     2\n",
      "6     0\n",
      "7     2\n",
      "8     2\n",
      "9     2\n",
      "10    2\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "27cf3f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 141)\n",
      "(7,)\n",
      "(4, 141)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "887ab3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "speech_detect_bagwords = MultinomialNB().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5256873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_b = speech_detect_bagwords.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aa6e9a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5aceca84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  1.0\n",
      "Test Score:  0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Score: \", speech_detect_bagwords.score(x_train, y_train))  # train score\n",
    "print(\"Test Score: \", speech_detect_bagwords.score(x_test, y_test)) #test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "da97c094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      1.00      0.50         1\n",
      "           2       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.50         4\n",
      "   macro avg       0.67      0.67      0.50         4\n",
      "weighted avg       0.83      0.50      0.50         4\n",
      "\n",
      "[[1 0]\n",
      " [2 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, predicted_b))\n",
    "print(metrics.confusion_matrix(y_test, predicted_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efd3d43",
   "metadata": {},
   "source": [
    "**Feature Extraction - TFIDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "04cf5339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer().fit(message_bagwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "964d2b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_tfidf = tfidf_transformer.transform(message_bagwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c5cdca8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 141)\n",
      "  (0, 109)\t0.408248290463863\n",
      "  (0, 89)\t0.408248290463863\n",
      "  (0, 68)\t0.408248290463863\n",
      "  (0, 65)\t0.408248290463863\n",
      "  (0, 18)\t0.408248290463863\n",
      "  (0, 7)\t0.408248290463863\n",
      "  (1, 137)\t0.17989195047387152\n",
      "  (1, 93)\t0.2966163024334637\n",
      "  (1, 86)\t0.2966163024334637\n",
      "  (1, 84)\t0.2535368170915251\n",
      "  (1, 76)\t0.19926308420735503\n",
      "  (1, 75)\t0.6689143074474305\n",
      "  (1, 66)\t0.2535368170915251\n",
      "  (1, 39)\t0.2966163024334637\n",
      "  (1, 29)\t0.2966163024334637\n",
      "  (2, 140)\t0.21747069819727116\n",
      "  (2, 138)\t0.14609406729165095\n",
      "  (2, 137)\t0.2637833979364459\n",
      "  (2, 132)\t0.16347636130279586\n",
      "  (2, 127)\t0.21747069819727116\n",
      "  (2, 122)\t0.21747069819727116\n",
      "  (2, 114)\t0.21747069819727116\n",
      "  (2, 107)\t0.21747069819727116\n",
      "  (2, 104)\t0.16347636130279586\n",
      "  (2, 103)\t0.21747069819727116\n",
      "  :\t:\n",
      "  (9, 85)\t0.2542429961579193\n",
      "  (9, 78)\t0.2542429961579193\n",
      "  (9, 38)\t0.2974424712949831\n",
      "  (9, 26)\t0.4471849615354321\n",
      "  (9, 20)\t0.2974424712949831\n",
      "  (9, 6)\t0.22359248076771604\n",
      "  (10, 139)\t0.22770460064113426\n",
      "  (10, 133)\t0.22770460064113426\n",
      "  (10, 131)\t0.22770460064113426\n",
      "  (10, 129)\t0.22770460064113426\n",
      "  (10, 128)\t0.22770460064113426\n",
      "  (10, 123)\t0.22770460064113426\n",
      "  (10, 105)\t0.22770460064113426\n",
      "  (10, 104)\t0.17116935694459456\n",
      "  (10, 101)\t0.22770460064113426\n",
      "  (10, 95)\t0.22770460064113426\n",
      "  (10, 79)\t0.22770460064113426\n",
      "  (10, 63)\t0.22770460064113426\n",
      "  (10, 51)\t0.1946336031095264\n",
      "  (10, 47)\t0.22770460064113426\n",
      "  (10, 41)\t0.22770460064113426\n",
      "  (10, 40)\t0.22770460064113426\n",
      "  (10, 31)\t0.1946336031095264\n",
      "  (10, 26)\t0.34233871388918913\n",
      "  (10, 3)\t0.22770460064113426\n"
     ]
    }
   ],
   "source": [
    "print(message_tfidf.shape)\n",
    "print(message_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7a351594",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = message_tfidf\n",
    "Y = df[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3f91be31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 109)\t0.408248290463863\n",
      "  (0, 89)\t0.408248290463863\n",
      "  (0, 68)\t0.408248290463863\n",
      "  (0, 65)\t0.408248290463863\n",
      "  (0, 18)\t0.408248290463863\n",
      "  (0, 7)\t0.408248290463863\n",
      "  (1, 137)\t0.17989195047387152\n",
      "  (1, 93)\t0.2966163024334637\n",
      "  (1, 86)\t0.2966163024334637\n",
      "  (1, 84)\t0.2535368170915251\n",
      "  (1, 76)\t0.19926308420735503\n",
      "  (1, 75)\t0.6689143074474305\n",
      "  (1, 66)\t0.2535368170915251\n",
      "  (1, 39)\t0.2966163024334637\n",
      "  (1, 29)\t0.2966163024334637\n",
      "  (2, 140)\t0.21747069819727116\n",
      "  (2, 138)\t0.14609406729165095\n",
      "  (2, 137)\t0.2637833979364459\n",
      "  (2, 132)\t0.16347636130279586\n",
      "  (2, 127)\t0.21747069819727116\n",
      "  (2, 122)\t0.21747069819727116\n",
      "  (2, 114)\t0.21747069819727116\n",
      "  (2, 107)\t0.21747069819727116\n",
      "  (2, 104)\t0.16347636130279586\n",
      "  (2, 103)\t0.21747069819727116\n",
      "  :\t:\n",
      "  (9, 85)\t0.2542429961579193\n",
      "  (9, 78)\t0.2542429961579193\n",
      "  (9, 38)\t0.2974424712949831\n",
      "  (9, 26)\t0.4471849615354321\n",
      "  (9, 20)\t0.2974424712949831\n",
      "  (9, 6)\t0.22359248076771604\n",
      "  (10, 139)\t0.22770460064113426\n",
      "  (10, 133)\t0.22770460064113426\n",
      "  (10, 131)\t0.22770460064113426\n",
      "  (10, 129)\t0.22770460064113426\n",
      "  (10, 128)\t0.22770460064113426\n",
      "  (10, 123)\t0.22770460064113426\n",
      "  (10, 105)\t0.22770460064113426\n",
      "  (10, 104)\t0.17116935694459456\n",
      "  (10, 101)\t0.22770460064113426\n",
      "  (10, 95)\t0.22770460064113426\n",
      "  (10, 79)\t0.22770460064113426\n",
      "  (10, 63)\t0.22770460064113426\n",
      "  (10, 51)\t0.1946336031095264\n",
      "  (10, 47)\t0.22770460064113426\n",
      "  (10, 41)\t0.22770460064113426\n",
      "  (10, 40)\t0.22770460064113426\n",
      "  (10, 31)\t0.1946336031095264\n",
      "  (10, 26)\t0.34233871388918913\n",
      "  (10, 3)\t0.22770460064113426\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "da82b1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1\n",
      "1     1\n",
      "2     2\n",
      "3     0\n",
      "4     2\n",
      "5     2\n",
      "6     0\n",
      "7     2\n",
      "8     2\n",
      "9     2\n",
      "10    2\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fb98dcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 141)\n",
      "(7,)\n",
      "(4, 141)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "08b3a4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    2\n",
      "1    1\n",
      "8    2\n",
      "4    2\n",
      "7    2\n",
      "3    0\n",
      "6    0\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "42d49d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     2\n",
       "0     1\n",
       "9     2\n",
       "10    2\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3fb1910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "speech_detect_tfidf = MultinomialNB().fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4b4f707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_t = speech_detect_tfidf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fe5e6223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2984acb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.8571428571428571\n",
      "Test Score:  0.75\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Score: \", speech_detect_tfidf.score(X_train, Y_train))  # train score\n",
    "print(\"Test Score: \", speech_detect_tfidf.score(X_test, Y_test)) #test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7b491864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.75         4\n",
      "   macro avg       0.38      0.50      0.43         4\n",
      "weighted avg       0.56      0.75      0.64         4\n",
      "\n",
      "[[0 1]\n",
      " [0 3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, predicted_t))\n",
    "print(metrics.confusion_matrix(y_test, predicted_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bce71538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f5f83fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test,predicted_b)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fdf2896e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test,predicted_t)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5905b330",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scalar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [106]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(speech_detect_tfidf,f)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msandardScalar.sav\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 7\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[43mscalar\u001b[49m,f)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scalar' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Writing different model files to file\n",
    "with open( 'modelForPrediction.sav', 'wb') as f:\n",
    "    pickle.dump(speech_detect_tfidf,f)\n",
    "    \n",
    "with open('sandardScalar.sav', 'wb') as f:\n",
    "    pickle.dump(scalar,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d34238f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1fbb8f9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 1 features, but MultinomialNB is expecting 141 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [109]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Make predictions using the trained model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m input_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0.408248290463863\u001b[39m]])  \u001b[38;5;66;03m# Replace with your input values\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mspeech_detect_tfidf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:82\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03mPerform classification on an array of test vectors X.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;124;03m    Predicted target values for X.\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     81\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m---> 82\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m jll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_joint_log_likelihood(X)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(jll, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:519\u001b[0m, in \u001b[0;36m_BaseDiscreteNB._check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_X\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;124;03m\"\"\"Validate X, used only in predict* methods.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 1 features, but MultinomialNB is expecting 141 features as input."
     ]
    }
   ],
   "source": [
    "# Make predictions using the trained model\n",
    "input_values = np.array([[0.408248290463863]])  # Replace with your input values\n",
    "predictions = speech_detect_tfidf.predict(input_values)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0200bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
